集成学习--用不同的算法计算后投票获取最终结果的方式
硬投票和软投票
    更专业的投票的权值应该更高一些
    不同模型地
    软投票--用不同模型地预测的平均概率作为投票权值--用概率决定结果

所以软投票需要使用支持估计概率的算法才能使用
knn
decision tree
logistic regression
svm --probability

需要更多的投票者，才能获得好的结果--创建很多的子模型
子模型之间要有差异性--子模型只处理样本的一部分
集成诸多的子模型，来的到投票结果 -每个子模型不需要太高的准确率（必须要比平均的准确率要高）例如：投硬币>50% 大量投票的结果就是正确的

OOB --Out-Of-Bag
    平均约有37%的样本没有被取到

如何创建差异性？
每个模型只看样本数据的一部分
取样：
    放回取样 Bagging（统计学中-bootstrap）
    不放回取样 Pasting-依赖随机